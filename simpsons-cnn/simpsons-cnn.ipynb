{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7248b289",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04c34aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File managing\n",
    "import os, zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Data wrangling and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# CNN\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization,\n",
    "                                     MaxPooling2D, Dropout,\n",
    "                                     GlobalAveragePooling2D, Dense)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Evaluation\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "SEED = 333\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ac8a87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb7e07",
   "metadata": {},
   "source": [
    "## 01 Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47aebac",
   "metadata": {},
   "source": [
    "### Clean Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079a1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./data/simpsons\n",
      "Deleted: ./data/simpsons_split\n",
      "Does not exist: ./data/simpsons_top_18\n",
      "Deleted: ./models\n"
     ]
    }
   ],
   "source": [
    "folders_to_clear = ['./data/simpsons', './data/simpsons_split', './models']\n",
    "\n",
    "for folder in folders_to_clear:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"Deleted: {folder}\")\n",
    "    else:\n",
    "        print(f\"Does not exist: {folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8139d1",
   "metadata": {},
   "source": [
    "### Extract Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc329965",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_PATH  = Path(\"data/simpsons.zip\")\n",
    "ROOT_DATA_PATH = Path(\"data/\")\n",
    "DATA_PATH = Path(\"data/simpsons/\")\n",
    "\n",
    "# Unzip \n",
    "if not ROOT_DATA_PATH.exists():\n",
    "    ROOT_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "    z.extractall(ROOT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823cf74",
   "metadata": {},
   "source": [
    "### Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f17ed057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homer_simpson: 2246\n",
      "ned_flanders: 1454\n",
      "moe_szyslak: 1452\n",
      "lisa_simpson: 1354\n",
      "bart_simpson: 1342\n",
      "marge_simpson: 1291\n",
      "krusty_the_clown: 1206\n",
      "principal_skinner: 1194\n",
      "charles_montgomery_burns: 1193\n",
      "milhouse_van_houten: 1079\n",
      "chief_wiggum: 986\n",
      "abraham_grampa_simpson: 913\n",
      "sideshow_bob: 877\n",
      "apu_nahasapeemapetilon: 623\n",
      "kent_brockman: 498\n",
      "comic_book_guy: 469\n",
      "edna_krabappel: 457\n",
      "nelson_muntz: 358\n",
      "lenny_leonard: 310\n",
      "mayor_quimby: 246\n",
      "waylon_smithers: 181\n",
      "maggie_simpson: 128\n",
      "groundskeeper_willie: 121\n",
      "barney_gumble: 106\n",
      "selma_bouvier: 103\n",
      "carl_carlson: 98\n",
      "ralph_wiggum: 89\n",
      "patty_bouvier: 72\n",
      "martin_prince: 71\n",
      "professor_john_frink: 65\n",
      "snake_jailbird: 55\n",
      "cletus_spuckler: 47\n",
      "rainier_wolfcastle: 45\n",
      "agnes_skinner: 42\n",
      "sideshow_mel: 40\n",
      "otto_mann: 32\n",
      "fat_tony: 27\n",
      "gil: 27\n",
      "miss_hoover: 17\n",
      "disco_stu: 8\n",
      "troy_mcclure: 8\n",
      "lionel_hutz: 3\n",
      "\n",
      "Top 18 classes: {'apu_nahasapeemapetilon', 'principal_skinner', 'sideshow_bob', 'marge_simpson', 'lisa_simpson', 'moe_szyslak', 'kent_brockman', 'homer_simpson', 'edna_krabappel', 'milhouse_van_houten', 'nelson_muntz', 'abraham_grampa_simpson', 'chief_wiggum', 'comic_book_guy', 'ned_flanders', 'bart_simpson', 'charles_montgomery_burns', 'krusty_the_clown'}\n"
     ]
    }
   ],
   "source": [
    "# read filenames \n",
    "filenames = [f for f in os.listdir(DATA_PATH) if f.endswith(\".jpg\")]\n",
    "\n",
    "# extract character names before _pic\n",
    "classes = [filename.split(\"_pic\")[0] for filename in filenames]\n",
    "\n",
    "# count class distribution\n",
    "class_counts = Counter(classes)\n",
    "\n",
    "# print the distribution\n",
    "for cl, count in class_counts.most_common():\n",
    "    print(f\"{cl}: {count}\")\n",
    "\n",
    "# only get the top 18 classes\n",
    "top_classes = {cl for cl, _ in class_counts.most_common(18)}\n",
    "print(\"\\nTop 18 classes:\", top_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2bab951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of images in data/simpsons: 20933\n"
     ]
    }
   ],
   "source": [
    "image_count = len([\n",
    "    f for f in os.listdir(DATA_PATH)\n",
    "    if f.lower().endswith((\".jpg\"))\n",
    "])\n",
    "\n",
    "print(f\"Total of images in {DATA_PATH}: {image_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518e24b",
   "metadata": {},
   "source": [
    "## 02 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee290e2",
   "metadata": {},
   "source": [
    "### Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2628587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train counts: {'abraham_grampa_simpson': 639, 'apu_nahasapeemapetilon': 436, 'bart_simpson': 939, 'charles_montgomery_burns': 835, 'chief_wiggum': 690, 'comic_book_guy': 328, 'edna_krabappel': 319, 'homer_simpson': 1572, 'kent_brockman': 348, 'krusty_the_clown': 844, 'lisa_simpson': 947, 'marge_simpson': 903, 'milhouse_van_houten': 755, 'moe_szyslak': 1016, 'ned_flanders': 1017, 'nelson_muntz': 250, 'principal_skinner': 835, 'sideshow_bob': 613}\n",
      "Val counts: {'abraham_grampa_simpson': 182, 'apu_nahasapeemapetilon': 124, 'bart_simpson': 268, 'charles_montgomery_burns': 238, 'chief_wiggum': 197, 'comic_book_guy': 93, 'edna_krabappel': 91, 'homer_simpson': 449, 'kent_brockman': 99, 'krusty_the_clown': 241, 'lisa_simpson': 270, 'marge_simpson': 258, 'milhouse_van_houten': 215, 'moe_szyslak': 290, 'ned_flanders': 290, 'nelson_muntz': 71, 'principal_skinner': 238, 'sideshow_bob': 175}\n",
      "Test counts: {'abraham_grampa_simpson': 92, 'apu_nahasapeemapetilon': 63, 'bart_simpson': 135, 'charles_montgomery_burns': 120, 'chief_wiggum': 99, 'comic_book_guy': 48, 'edna_krabappel': 47, 'homer_simpson': 225, 'kent_brockman': 51, 'krusty_the_clown': 121, 'lisa_simpson': 137, 'marge_simpson': 130, 'milhouse_van_houten': 109, 'moe_szyslak': 146, 'ned_flanders': 147, 'nelson_muntz': 37, 'principal_skinner': 121, 'sideshow_bob': 89}\n"
     ]
    }
   ],
   "source": [
    "SPLIT_PATH = ROOT_DATA_PATH / \"simpsons_split\"\n",
    "TRAIN_DIR  = SPLIT_PATH / \"train\"\n",
    "VAL_DIR    = SPLIT_PATH / \"val\"\n",
    "TEST_DIR   = SPLIT_PATH / \"test\"\n",
    "\n",
    "random.seed(333)\n",
    "\n",
    "for split_dir in (TRAIN_DIR, VAL_DIR, TEST_DIR):\n",
    "    for cl in top_classes:\n",
    "        (split_dir / cl).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any((TRAIN_DIR / next(iter(top_classes))).iterdir()):\n",
    "    for cl in top_classes:\n",
    "        cl_files = sorted([f for f in filenames if f.startswith(f\"{cl}_pic\")])\n",
    "        random.shuffle(cl_files)\n",
    "\n",
    "        n_total  = len(cl_files)\n",
    "        n_train  = int(0.70 * n_total)\n",
    "        n_val    = int(0.20 * n_total)\n",
    "\n",
    "        for i, src_name in enumerate(cl_files):\n",
    "            src = DATA_PATH / src_name\n",
    "            if i < n_train:\n",
    "                dst = TRAIN_DIR / cl / src_name\n",
    "            elif i < n_train + n_val:\n",
    "                dst = VAL_DIR / cl / src_name\n",
    "            else:\n",
    "                dst = TEST_DIR / cl / src_name\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "def count_per_split(split_dir):\n",
    "    return {cls: len(list((split_dir/cls).iterdir()))\n",
    "            for cls in sorted(top_classes)}\n",
    "\n",
    "print(\"Train counts:\", count_per_split(TRAIN_DIR))\n",
    "print(\"Val counts:\",   count_per_split(VAL_DIR))\n",
    "print(\"Test counts:\",  count_per_split(TEST_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a2ba1",
   "metadata": {},
   "source": [
    "### ImageDataGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e57b4be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13286 images belonging to 18 classes.\n",
      "Found 3789 images belonging to 18 classes.\n",
      "Found 1917 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = (128, 192)\n",
    "BATCH_SIZE  = 96\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "\n",
    "dgen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "dgen_val_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = dgen_train.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "validation_generator = dgen_val_test.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = dgen_val_test.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88361f",
   "metadata": {},
   "source": [
    "### Calcuate Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19dd1b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: np.float64(1.1551034602677794), 1: np.float64(1.6929153924566769), 2: np.float64(0.7860608212045912), 3: np.float64(0.8839654025282768), 4: np.float64(1.0697262479871175), 5: np.float64(2.250338753387534), 6: np.float64(2.31382793451759), 7: np.float64(0.4695363302233531), 8: np.float64(2.121008939974457), 9: np.float64(0.8745392311743022), 10: np.float64(0.7794203918807932), 11: np.float64(0.8173987941429802), 12: np.float64(0.9776306107431936), 13: np.float64(0.7264873140857393), 14: np.float64(0.7257729706107288), 15: np.float64(2.9524444444444446), 16: np.float64(0.8839654025282768), 17: np.float64(1.2040964292187784)}\n"
     ]
    }
   ],
   "source": [
    "train_counts = np.array(list(count_per_split(TRAIN_DIR).values()))\n",
    "class_indices = train_generator.class_indices \n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(class_indices)),\n",
    "    y=np.repeat(\n",
    "        list(class_indices.values()),\n",
    "        train_counts\n",
    "    )\n",
    ")\n",
    "class_weight = dict(enumerate(weights))\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56f8d5",
   "metadata": {},
   "source": [
    "## 03 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "062efbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,626</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m4,626\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">325,554</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m325,554\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">325,106</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m325,106\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_SIZE = TARGET_SIZE\n",
    "INPUT_SHAPE  = (*IMG_SIZE, 3)\n",
    "NUM_CLASSES  = train_generator.num_classes\n",
    "\n",
    "# define layers\n",
    "model = Sequential([\n",
    "    Input(shape=INPUT_SHAPE),\n",
    "\n",
    "    # First Convolutional Block\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Third  Convolutional Block\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.32),\n",
    "\n",
    "    #  Dense classifier layer\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax', dtype='float32')  # evita underflow si usas mixed precision\n",
    "])\n",
    "\n",
    "# optimizer and loss function setup\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# define training callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath= 'models/best_model_{epoch:02d}-{val_accuracy:.3f}.keras',\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e62462",
   "metadata": {},
   "source": [
    "## 04 CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e99f5312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vgnma/.pyenv/versions/UNAM_DataScience/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.1358 - loss: 2.7740\n",
      "Epoch 1: val_loss improved from inf to 3.03311, saving model to models/best_model_01-0.062.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 219ms/step - accuracy: 0.1361 - loss: 2.7726 - val_accuracy: 0.0623 - val_loss: 3.0331\n",
      "Epoch 2/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.3158 - loss: 2.1275\n",
      "Epoch 2: val_loss did not improve from 3.03311\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.3161 - loss: 2.1264 - val_accuracy: 0.0631 - val_loss: 3.5123\n",
      "Epoch 3/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.4718 - loss: 1.5992\n",
      "Epoch 3: val_loss improved from 3.03311 to 2.39413, saving model to models/best_model_03-0.278.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.4721 - loss: 1.5984 - val_accuracy: 0.2776 - val_loss: 2.3941\n",
      "Epoch 4/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6214 - loss: 1.1568\n",
      "Epoch 4: val_loss improved from 2.39413 to 1.40176, saving model to models/best_model_04-0.596.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.6216 - loss: 1.1563 - val_accuracy: 0.5959 - val_loss: 1.4018\n",
      "Epoch 5/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7246 - loss: 0.8424\n",
      "Epoch 5: val_loss did not improve from 1.40176\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.7246 - loss: 0.8423 - val_accuracy: 0.6466 - val_loss: 1.5279\n",
      "Epoch 6/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7652 - loss: 0.7197\n",
      "Epoch 6: val_loss improved from 1.40176 to 0.98711, saving model to models/best_model_06-0.710.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.7653 - loss: 0.7196 - val_accuracy: 0.7099 - val_loss: 0.9871\n",
      "Epoch 7/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7889 - loss: 0.6376\n",
      "Epoch 7: val_loss did not improve from 0.98711\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.7890 - loss: 0.6374 - val_accuracy: 0.7070 - val_loss: 1.0977\n",
      "Epoch 8/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8233 - loss: 0.5506\n",
      "Epoch 8: val_loss improved from 0.98711 to 0.80607, saving model to models/best_model_08-0.770.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.8233 - loss: 0.5506 - val_accuracy: 0.7699 - val_loss: 0.8061\n",
      "Epoch 9/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8459 - loss: 0.4813\n",
      "Epoch 9: val_loss improved from 0.80607 to 0.60095, saving model to models/best_model_09-0.844.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.8459 - loss: 0.4813 - val_accuracy: 0.8438 - val_loss: 0.6010\n",
      "Epoch 10/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8532 - loss: 0.4534\n",
      "Epoch 10: val_loss did not improve from 0.60095\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.8533 - loss: 0.4533 - val_accuracy: 0.7992 - val_loss: 0.9000\n",
      "Epoch 11/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8715 - loss: 0.4000\n",
      "Epoch 11: val_loss did not improve from 0.60095\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.8715 - loss: 0.4000 - val_accuracy: 0.7915 - val_loss: 0.8331\n",
      "Epoch 12/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8747 - loss: 0.3889\n",
      "Epoch 12: val_loss did not improve from 0.60095\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.8747 - loss: 0.3889 - val_accuracy: 0.8187 - val_loss: 0.6860\n",
      "Epoch 13/100\n",
      "\u001b[1m138/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8887 - loss: 0.3423\n",
      "Epoch 13: val_loss improved from 0.60095 to 0.50010, saving model to models/best_model_13-0.867.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.8886 - loss: 0.3424 - val_accuracy: 0.8667 - val_loss: 0.5001\n",
      "Epoch 14/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8911 - loss: 0.3288\n",
      "Epoch 14: val_loss did not improve from 0.50010\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 194ms/step - accuracy: 0.8911 - loss: 0.3288 - val_accuracy: 0.7891 - val_loss: 1.0199\n",
      "Epoch 15/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9003 - loss: 0.3132\n",
      "Epoch 15: val_loss did not improve from 0.50010\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9003 - loss: 0.3133 - val_accuracy: 0.7960 - val_loss: 0.8512\n",
      "Epoch 16/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8961 - loss: 0.3208\n",
      "Epoch 16: val_loss did not improve from 0.50010\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.8961 - loss: 0.3208 - val_accuracy: 0.7941 - val_loss: 0.8248\n",
      "Epoch 17/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9020 - loss: 0.2988\n",
      "Epoch 17: val_loss did not improve from 0.50010\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9020 - loss: 0.2987 - val_accuracy: 0.8577 - val_loss: 0.5911\n",
      "Epoch 18/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9119 - loss: 0.2672\n",
      "Epoch 18: val_loss improved from 0.50010 to 0.37803, saving model to models/best_model_18-0.903.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9119 - loss: 0.2672 - val_accuracy: 0.9034 - val_loss: 0.3780\n",
      "Epoch 19/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9171 - loss: 0.2552\n",
      "Epoch 19: val_loss improved from 0.37803 to 0.33636, saving model to models/best_model_19-0.913.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9171 - loss: 0.2552 - val_accuracy: 0.9129 - val_loss: 0.3364\n",
      "Epoch 20/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9169 - loss: 0.2466\n",
      "Epoch 20: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9169 - loss: 0.2466 - val_accuracy: 0.8928 - val_loss: 0.4245\n",
      "Epoch 21/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9208 - loss: 0.2393\n",
      "Epoch 21: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 194ms/step - accuracy: 0.9208 - loss: 0.2393 - val_accuracy: 0.8918 - val_loss: 0.4527\n",
      "Epoch 22/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9246 - loss: 0.2193\n",
      "Epoch 22: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9246 - loss: 0.2193 - val_accuracy: 0.9105 - val_loss: 0.3697\n",
      "Epoch 23/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9259 - loss: 0.2299\n",
      "Epoch 23: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9259 - loss: 0.2299 - val_accuracy: 0.9023 - val_loss: 0.3792\n",
      "Epoch 24/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9285 - loss: 0.2200\n",
      "Epoch 24: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9285 - loss: 0.2200 - val_accuracy: 0.8905 - val_loss: 0.4051\n",
      "Epoch 25/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9326 - loss: 0.2025\n",
      "Epoch 25: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 195ms/step - accuracy: 0.9327 - loss: 0.2024 - val_accuracy: 0.8723 - val_loss: 0.4793\n",
      "Epoch 26/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9335 - loss: 0.2018\n",
      "Epoch 26: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9335 - loss: 0.2018 - val_accuracy: 0.8767 - val_loss: 0.5298\n",
      "Epoch 27/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9389 - loss: 0.1748\n",
      "Epoch 27: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9389 - loss: 0.1749 - val_accuracy: 0.8963 - val_loss: 0.4242\n",
      "Epoch 28/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9368 - loss: 0.2059\n",
      "Epoch 28: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9368 - loss: 0.2059 - val_accuracy: 0.7511 - val_loss: 1.3824\n",
      "Epoch 29/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9447 - loss: 0.1698\n",
      "Epoch 29: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9447 - loss: 0.1698 - val_accuracy: 0.9206 - val_loss: 0.3901\n",
      "Epoch 30/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9426 - loss: 0.1667\n",
      "Epoch 30: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9426 - loss: 0.1667 - val_accuracy: 0.9039 - val_loss: 0.3979\n",
      "Epoch 31/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9398 - loss: 0.1815\n",
      "Epoch 31: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9399 - loss: 0.1814 - val_accuracy: 0.9158 - val_loss: 0.3996\n",
      "Epoch 32/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9454 - loss: 0.1591\n",
      "Epoch 32: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9453 - loss: 0.1592 - val_accuracy: 0.9076 - val_loss: 0.3807\n",
      "Epoch 33/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9428 - loss: 0.1684\n",
      "Epoch 33: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9428 - loss: 0.1685 - val_accuracy: 0.8422 - val_loss: 0.7225\n",
      "Epoch 34/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9459 - loss: 0.1621\n",
      "Epoch 34: val_loss did not improve from 0.33636\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 195ms/step - accuracy: 0.9459 - loss: 0.1622 - val_accuracy: 0.9023 - val_loss: 0.4128\n",
      "Epoch 35/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9493 - loss: 0.1526\n",
      "Epoch 35: val_loss improved from 0.33636 to 0.33003, saving model to models/best_model_35-0.929.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 194ms/step - accuracy: 0.9493 - loss: 0.1527 - val_accuracy: 0.9293 - val_loss: 0.3300\n",
      "Epoch 36/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9518 - loss: 0.1372\n",
      "Epoch 36: val_loss did not improve from 0.33003\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9518 - loss: 0.1372 - val_accuracy: 0.8836 - val_loss: 0.4843\n",
      "Epoch 37/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9518 - loss: 0.1352\n",
      "Epoch 37: val_loss did not improve from 0.33003\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9518 - loss: 0.1353 - val_accuracy: 0.8870 - val_loss: 0.5098\n",
      "Epoch 38/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9492 - loss: 0.1497\n",
      "Epoch 38: val_loss improved from 0.33003 to 0.29508, saving model to models/best_model_38-0.937.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9492 - loss: 0.1497 - val_accuracy: 0.9367 - val_loss: 0.2951\n",
      "Epoch 39/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9497 - loss: 0.1449\n",
      "Epoch 39: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9498 - loss: 0.1448 - val_accuracy: 0.7933 - val_loss: 1.0965\n",
      "Epoch 40/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9509 - loss: 0.1559\n",
      "Epoch 40: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9509 - loss: 0.1559 - val_accuracy: 0.9272 - val_loss: 0.3556\n",
      "Epoch 41/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9553 - loss: 0.1291\n",
      "Epoch 41: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9553 - loss: 0.1291 - val_accuracy: 0.9369 - val_loss: 0.3086\n",
      "Epoch 42/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9589 - loss: 0.1217\n",
      "Epoch 42: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9589 - loss: 0.1217 - val_accuracy: 0.8189 - val_loss: 1.2275\n",
      "Epoch 43/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9574 - loss: 0.1292\n",
      "Epoch 43: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9574 - loss: 0.1292 - val_accuracy: 0.9111 - val_loss: 0.3564\n",
      "Epoch 44/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9587 - loss: 0.1219\n",
      "Epoch 44: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9587 - loss: 0.1219 - val_accuracy: 0.9140 - val_loss: 0.4037\n",
      "Epoch 45/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9578 - loss: 0.1282\n",
      "Epoch 45: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9578 - loss: 0.1282 - val_accuracy: 0.9116 - val_loss: 0.3699\n",
      "Epoch 46/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9569 - loss: 0.1140\n",
      "Epoch 46: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9569 - loss: 0.1141 - val_accuracy: 0.8868 - val_loss: 0.6730\n",
      "Epoch 47/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9600 - loss: 0.1197\n",
      "Epoch 47: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 195ms/step - accuracy: 0.9600 - loss: 0.1196 - val_accuracy: 0.9243 - val_loss: 0.3735\n",
      "Epoch 48/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9630 - loss: 0.1062\n",
      "Epoch 48: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9630 - loss: 0.1062 - val_accuracy: 0.9398 - val_loss: 0.2998\n",
      "Epoch 49/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9584 - loss: 0.1237\n",
      "Epoch 49: val_loss did not improve from 0.29508\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9584 - loss: 0.1236 - val_accuracy: 0.9311 - val_loss: 0.3036\n",
      "Epoch 50/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9623 - loss: 0.1108\n",
      "Epoch 50: val_loss improved from 0.29508 to 0.27895, saving model to models/best_model_50-0.937.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9623 - loss: 0.1109 - val_accuracy: 0.9369 - val_loss: 0.2789\n",
      "Epoch 51/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9617 - loss: 0.1200\n",
      "Epoch 51: val_loss did not improve from 0.27895\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 194ms/step - accuracy: 0.9616 - loss: 0.1200 - val_accuracy: 0.7699 - val_loss: 2.1379\n",
      "Epoch 52/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9682 - loss: 0.1002\n",
      "Epoch 52: val_loss did not improve from 0.27895\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9682 - loss: 0.1003 - val_accuracy: 0.9008 - val_loss: 0.4267\n",
      "Epoch 53/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9678 - loss: 0.0952\n",
      "Epoch 53: val_loss did not improve from 0.27895\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9677 - loss: 0.0952 - val_accuracy: 0.9324 - val_loss: 0.3197\n",
      "Epoch 54/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9664 - loss: 0.0942\n",
      "Epoch 54: val_loss improved from 0.27895 to 0.23431, saving model to models/best_model_54-0.956.keras\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9664 - loss: 0.0941 - val_accuracy: 0.9562 - val_loss: 0.2343\n",
      "Epoch 55/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9704 - loss: 0.0920\n",
      "Epoch 55: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9703 - loss: 0.0921 - val_accuracy: 0.9150 - val_loss: 0.4251\n",
      "Epoch 56/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9659 - loss: 0.0963\n",
      "Epoch 56: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9658 - loss: 0.0963 - val_accuracy: 0.9264 - val_loss: 0.3366\n",
      "Epoch 57/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9652 - loss: 0.1030\n",
      "Epoch 57: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9652 - loss: 0.1030 - val_accuracy: 0.8232 - val_loss: 0.9725\n",
      "Epoch 58/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9695 - loss: 0.0885\n",
      "Epoch 58: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 195ms/step - accuracy: 0.9695 - loss: 0.0885 - val_accuracy: 0.8255 - val_loss: 1.0505\n",
      "Epoch 59/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9700 - loss: 0.0921\n",
      "Epoch 59: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 191ms/step - accuracy: 0.9700 - loss: 0.0920 - val_accuracy: 0.9454 - val_loss: 0.2654\n",
      "Epoch 60/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9680 - loss: 0.0888\n",
      "Epoch 60: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9680 - loss: 0.0889 - val_accuracy: 0.9433 - val_loss: 0.2973\n",
      "Epoch 61/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9673 - loss: 0.1010\n",
      "Epoch 61: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9673 - loss: 0.1010 - val_accuracy: 0.9470 - val_loss: 0.2848\n",
      "Epoch 62/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9652 - loss: 0.0984\n",
      "Epoch 62: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 190ms/step - accuracy: 0.9653 - loss: 0.0984 - val_accuracy: 0.9037 - val_loss: 0.4958\n",
      "Epoch 63/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9690 - loss: 0.0888\n",
      "Epoch 63: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9690 - loss: 0.0887 - val_accuracy: 0.9409 - val_loss: 0.2968\n",
      "Epoch 64/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9704 - loss: 0.0900\n",
      "Epoch 64: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9704 - loss: 0.0900 - val_accuracy: 0.9295 - val_loss: 0.3342\n",
      "Epoch 65/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9732 - loss: 0.0876\n",
      "Epoch 65: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9731 - loss: 0.0876 - val_accuracy: 0.9417 - val_loss: 0.3258\n",
      "Epoch 66/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9714 - loss: 0.0841\n",
      "Epoch 66: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9714 - loss: 0.0841 - val_accuracy: 0.9345 - val_loss: 0.3091\n",
      "Epoch 67/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9734 - loss: 0.0758\n",
      "Epoch 67: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9734 - loss: 0.0759 - val_accuracy: 0.9229 - val_loss: 0.3812\n",
      "Epoch 68/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9692 - loss: 0.0876\n",
      "Epoch 68: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9693 - loss: 0.0876 - val_accuracy: 0.9034 - val_loss: 0.5558\n",
      "Epoch 69/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9710 - loss: 0.0840\n",
      "Epoch 69: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9710 - loss: 0.0840 - val_accuracy: 0.9425 - val_loss: 0.3179\n",
      "Epoch 70/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9682 - loss: 0.0853\n",
      "Epoch 70: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9682 - loss: 0.0853 - val_accuracy: 0.9535 - val_loss: 0.2391\n",
      "Epoch 71/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9759 - loss: 0.0751\n",
      "Epoch 71: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9759 - loss: 0.0751 - val_accuracy: 0.9446 - val_loss: 0.2870\n",
      "Epoch 72/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9755 - loss: 0.0671\n",
      "Epoch 72: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 193ms/step - accuracy: 0.9755 - loss: 0.0672 - val_accuracy: 0.9192 - val_loss: 0.4724\n",
      "Epoch 73/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9749 - loss: 0.0757\n",
      "Epoch 73: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 194ms/step - accuracy: 0.9749 - loss: 0.0757 - val_accuracy: 0.9134 - val_loss: 0.4801\n",
      "Epoch 74/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9722 - loss: 0.0802\n",
      "Epoch 74: val_loss did not improve from 0.23431\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 192ms/step - accuracy: 0.9722 - loss: 0.0802 - val_accuracy: 0.9430 - val_loss: 0.3252\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "773f890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e327f2",
   "metadata": {},
   "source": [
    "## 05 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "631170bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "  abraham_grampa_simpson       0.92      0.96      0.94        92\n",
      "  apu_nahasapeemapetilon       0.98      0.97      0.98        63\n",
      "            bart_simpson       0.96      0.92      0.94       135\n",
      "charles_montgomery_burns       0.93      0.95      0.94       120\n",
      "            chief_wiggum       0.94      0.98      0.96        99\n",
      "          comic_book_guy       0.90      0.96      0.93        48\n",
      "          edna_krabappel       0.98      0.96      0.97        47\n",
      "           homer_simpson       0.95      0.94      0.95       225\n",
      "           kent_brockman       0.94      1.00      0.97        51\n",
      "        krusty_the_clown       0.95      0.95      0.95       121\n",
      "            lisa_simpson       0.96      0.95      0.95       137\n",
      "           marge_simpson       0.96      0.95      0.96       130\n",
      "     milhouse_van_houten       1.00      0.96      0.98       109\n",
      "             moe_szyslak       0.95      0.95      0.95       146\n",
      "            ned_flanders       1.00      0.97      0.99       147\n",
      "            nelson_muntz       0.92      0.95      0.93        37\n",
      "       principal_skinner       0.95      0.98      0.97       121\n",
      "            sideshow_bob       0.98      0.97      0.97        89\n",
      "\n",
      "                accuracy                           0.96      1917\n",
      "               macro avg       0.95      0.96      0.96      1917\n",
      "            weighted avg       0.96      0.96      0.96      1917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true       = test_generator.classes\n",
    "y_pred_prob  = model.predict(test_generator, verbose=0)\n",
    "y_pred       = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "print(classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNAM_DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
